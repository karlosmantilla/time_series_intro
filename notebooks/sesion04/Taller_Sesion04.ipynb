{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1><font size=\"16\">Especializaci√≥n en Estad√≠stica</font></h1>\n",
    "    <h1><font size=\"12\">SERIES DE TIEMPO</font></h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Taller Pr√°ctico ‚Äì Modelos Avanzados para Series Temporales: Estado Espacial, Redes Neuronales y GAMs\n",
    "\n",
    "### üìò **Introducci√≥n**\n",
    "\n",
    "En este taller exploraremos **modelos avanzados aplicados a series temporales**, poniendo √©nfasis en aquellos que permiten capturar patrones complejos como **tendencia, estacionalidad no lineal y din√°micas estructurales latentes**. A diferencia de enfoques cl√°sicos como ARIMA, estos modelos ofrecen mayor flexibilidad para representar la evoluci√≥n temporal de un fen√≥meno y generar pron√≥sticos informados.\n",
    "\n",
    "Nos centraremos en tres tipos de modelos:\n",
    "\n",
    "1. **Modelos de Estado Espacial**: permiten descomponer la serie en componentes latentes (nivel, pendiente, estacionalidad) y realizar pron√≥sticos robustos mediante el filtro de Kalman.\n",
    "2. **Redes Neuronales**: ofrecen una aproximaci√≥n no param√©trica para capturar relaciones no lineales a partir de rezagos temporales, incluyendo modelos autoregresivos y recurrentes.\n",
    "3. **Modelos Aditivos Generalizados (GAMs)**: permiten modelar suavizadamente los efectos del tiempo y la estacionalidad mediante funciones spline, con alta interpretabilidad estructural.\n",
    "\n",
    "> üß† Este taller no se centra en la construcci√≥n desde cero de los modelos, sino en **analizar, interpretar y comparar los resultados obtenidos**, incluyendo su descomposici√≥n, visualizaci√≥n y capacidad predictiva.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Objetivos del Taller**\n",
    "\n",
    "* Analizar e interpretar los componentes latentes estimados por modelos de estado espacial.\n",
    "* Comparar la capacidad predictiva de distintos enfoques neuronales aplicados a una misma serie.\n",
    "* Evaluar la descomposici√≥n y ajuste realizado por un modelo GAM en t√©rminos de tendencia y estacionalidad.\n",
    "* Visualizar y comunicar de forma efectiva los resultados de cada modelo y su aplicabilidad en contextos reales.\n",
    "\n",
    "---\n",
    "\n",
    "### üß∞ **Requisitos Previos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(KFAS)      # Modelos de estado espacial y filtro de Kalman con estructura flexible.\n",
    "library(dlm)       # Alternativa para modelos de estado espacial con enfoque bayesiano/cl√°sico.\n",
    "library(mgcv)      # Modelos Aditivos Generalizados (GAMs) con funciones suavizadas tipo spline.\n",
    "\n",
    "library(tsDyn)     # Modelos autoregresivos no lineales con redes neuronales (`nnetTs`).\n",
    "library(nnet)      # Redes neuronales cl√°sicas (perceptrones multicapa).\n",
    "library(RSNNS)     # Implementaci√≥n de redes neuronales recurrentes (Elman, Jordan) y avanzadas.\n",
    "library(caret)     # Framework unificado para entrenamiento y validaci√≥n de modelos (incluye redes neuronales).\n",
    "\n",
    "library(fpp3)      # Framework moderno para an√°lisis de series temporales con `tsibble`, `fable` y `ggplot2`.\n",
    "library(forecast)  # Modelos cl√°sicos de pron√≥stico y funciones auxiliares (`nnetar`, `forecast`, `accuracy`).\n",
    "library(ggplot2)   # Visualizaci√≥n de series, componentes suavizados y pron√≥sticos.\n",
    "library(zoo)       # Manipulaci√≥n de series temporales indexadas y conversi√≥n a `yearmon`.\n",
    "library(lubridate) # Extracci√≥n y manejo de componentes temporales (a√±o, mes).\n",
    "library(tibble)    # Estructura moderna de data frames para flujos `tidy`.\n",
    "library(dplyr)     # Manipulaci√≥n eficiente y legible de datos (`mutate`, `filter`, `join`, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì• 1. Carga y transformaci√≥n de datos\n",
    "\n",
    "Trabajaremos con la serie mensual de pasajeros a√©reos internacionales (`AirPassengers`), incluida por defecto en R. Esta serie contiene 144 observaciones mensuales desde enero de 1949 hasta diciembre de 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la serie\n",
    "data(\"AirPassengers\")\n",
    "ap <- AirPassengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç **Descripci√≥n**:\n",
    "\n",
    "* La serie representa el n√∫mero de pasajeros (en miles) que viajaron por avi√≥n cada mes.\n",
    "* Se trata de una serie **no estacionaria**, tanto en media como en varianza.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÑ Transformaci√≥n logar√≠tmica\n",
    "\n",
    "Aplicamos la transformaci√≥n logar√≠tmica para **estabilizar la varianza** y facilitar la interpretaci√≥n en algunos modelos, como los de estado espacial, redes neuronales y GAMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar a logaritmo natural\n",
    "log_ap <- log(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üß† Esta transformaci√≥n convierte los incrementos relativos en incrementos absolutos y suaviza la amplitud creciente de la estacionalidad.\n",
    "\n",
    "### üß± **2. Definici√≥n del modelo de estado espacial estructural**\n",
    "\n",
    "Iniciaremos con la construcci√≥n de un **modelo estructural cl√°sico** que descompone la serie en dos componentes principales:\n",
    "\n",
    "1. Una **tendencia local** con nivel y pendiente.\n",
    "2. Una **estacionalidad mensual** representada mediante variables dummy.\n",
    "\n",
    "Trabajamos sobre la serie en escala logar√≠tmica, por lo que los efectos **multiplicativos se vuelven aditivos** en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo estructural: tendencia local + estacionalidad\n",
    "modelo_ss <- SSModel(log_ap ~ \n",
    "                       SSMtrend(degree = 2, Q = list(matrix(NA), matrix(NA))) +\n",
    "                       SSMseasonal(period = 12, sea.type = \"dummy\", Q = matrix(NA)),\n",
    "                     H = matrix(NA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß† Explicaci√≥n de los componentes\n",
    "\n",
    "| Componente                        | Descripci√≥n                                                                                                           |\n",
    "| :-------------------------------- | :-------------------------------------------------------------------------------------------------------------------- |\n",
    "| `SSMtrend(degree = 2)`            | Modelo de **tendencia local lineal**, con dos estados: `nivel` y `pendiente`.                                         |\n",
    "| `SSMseasonal(period = 12, dummy)` | Modelo de **estacionalidad mensual** con 11 variables dummy (meses).                                                  |\n",
    "| `Q = list(...)`                   | Matriz de varianzas de los errores de estado (nivel, pendiente, estacionalidad). Se estiman por m√°xima verosimilitud. |\n",
    "| `H = matrix(NA)`                  | Varianza del error de observaci√≥n (ruido blanco). Tambi√©n estimada.                                                   |\n",
    "\n",
    "---\n",
    "\n",
    "> üìå Este modelo es completamente **probabil√≠stico y din√°mico**, y permite analizar c√≥mo evolucionan separadamente el nivel de la serie y la estacionalidad mes a mes.\n",
    "\n",
    "### üßÆ **3. Estimaci√≥n del modelo y aplicaci√≥n del Filtro de Kalman**\n",
    "\n",
    "Una vez definido el modelo estructural, el siguiente paso es **estimar los par√°metros desconocidos** (las varianzas en $Q$ y $H$) mediante **m√°xima verosimilitud**, y luego aplicar el **Filtro de Kalman** para obtener los valores suavizados de los componentes latentes.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî¢ Estimaci√≥n de par√°metros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores iniciales (en log-escala) para las varianzas:\n",
    "# Orden: H (observaci√≥n), Q1 (nivel), Q2 (pendiente), Q3 (estacionalidad)\n",
    "iniciales <- log(c(0.01, 0.001, 0.001, 0.01))\n",
    "\n",
    "# Estimaci√≥n con m√©todo de optimizaci√≥n BFGS\n",
    "fit <- fitSSM(modelo_ss, inits = iniciales, method = \"BFGS\")\n",
    "\n",
    "# Extraer modelo ajustado con par√°metros estimados\n",
    "modelo_ajustado <- fit$model\n",
    "\n",
    "# Visualizar resumen del modelo ajustado\n",
    "modelo_ajustado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Explicaci√≥n\n",
    "\n",
    "* `fitSSM()` realiza la optimizaci√≥n de la verosimilitud para estimar los par√°metros libres (valores `NA` en Q y H).\n",
    "* Se usa el m√©todo **BFGS**, eficiente para problemas diferenciables.\n",
    "* `modelo_ajustado` contiene ya los valores estimados y est√° listo para aplicar el **Filtro de Kalman**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üö¶ Aplicar Filtro de Kalman + suavizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar filtro de Kalman y suavizado de estados\n",
    "kfs <- KFS(modelo_ajustado, smoothing = c(\"state\", \"signal\"))\n",
    "\n",
    "# Inspeccionar resumen del objeto\n",
    "kfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç ¬øQu√© contiene `kfs`?\n",
    "\n",
    "* `kfs$alphahat`: valores suavizados de los **estados latentes** (nivel, pendiente, estacionalidad).\n",
    "* `kfs$muhat`: serie suavizada reconstruida a partir de los componentes estimados.\n",
    "* `kfs$V`: varianza de predicci√≥n.\n",
    "* `kfs$v`: residuos de predicci√≥n.\n",
    "\n",
    "Estos resultados se usar√°n en los pasos siguientes para **visualizar la tendencia, la estacionalidad y realizar pron√≥sticos**.\n",
    "\n",
    "### üí¨ Preguntas\n",
    "\n",
    "1. ¬øQu√© representa cada uno de los componentes del modelo de estado espacial (nivel, pendiente, estacionalidad)?\n",
    "2. ¬øQu√© ventaja tiene representar la estacionalidad mediante variables dummy frente a usar funciones senoidales o splines?\n",
    "3. ¬øQu√© nos dice el comportamiento del componente estacional sobre los ciclos anuales en la serie?\n",
    "4. ¬øQu√© diferencia habr√≠a si us√°ramos una estacionalidad `bs = \"cc\"` con splines c√≠clicos como en GAMs?\n",
    "\n",
    "---\n",
    "\n",
    "### üìä **4. Visualizaci√≥n de componentes suavizados**\n",
    "\n",
    "Despu√©s de aplicar el filtro y suavizado de Kalman, es posible **descomponer la serie observada** en sus componentes latentes estimados: **nivel**, **pendiente** y **estacionalidad**.\n",
    "\n",
    "En esta secci√≥n, visualizaremos c√≥mo se comporta la **tendencia suavizada** en comparaci√≥n con la serie original transformada.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Preparar los datos para graficar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto ts con los componentes del modelo\n",
    "ts_comp <- ts(cbind(\n",
    "  Observado = log_ap,\n",
    "  Tendencia = kfs$muhat,\n",
    "  Nivel = kfs$alphahat[, \"level\"],\n",
    "  Pendiente = kfs$alphahat[, \"slope\"],\n",
    "  Estacionalidad = kfs$alphahat[, grepl(\"sea\", colnames(kfs$alphahat))]\n",
    "), start = start(log_ap), frequency = frequency(log_ap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç Aqu√≠ estamos construyendo una serie multivariada `ts` con:\n",
    "\n",
    "* La serie observada (`log_ap`).\n",
    "* La serie suavizada completa (`muhat`), que incluye todos los componentes.\n",
    "* Los estados individuales: `nivel`, `pendiente`, y la **suma de efectos estacionales** (`sea_dummy1`, ..., `sea_dummy11`).\n",
    "\n",
    "---\n",
    "\n",
    "#### üìÜ Construir un data frame con fechas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo)\n",
    "library(lubridate)\n",
    "library(ggplot2)\n",
    "\n",
    "# Extraer fechas a partir del √≠ndice de tiempo\n",
    "fechas <- as.yearmon(time(ts_comp))\n",
    "\n",
    "# Crear data.frame con observaciones y tendencia\n",
    "df_comp <- data.frame(\n",
    "  Fecha = as.Date(fechas),\n",
    "  Observado = as.numeric(ts_comp[, \"Observado\"]),\n",
    "  Tendencia = as.numeric(ts_comp[, \"Tendencia\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Graficar la tendencia suavizada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_comp, aes(x = Fecha)) +\n",
    "  geom_line(aes(y = Observado), color = \"black\", linewidth = 0.8) +\n",
    "  geom_line(aes(y = Tendencia), color = \"blue\", linewidth = 0.8, linetype = \"dashed\") +\n",
    "  labs(title = \"Observado vs Tendencia (modelo de estado espacial)\",\n",
    "       y = \"log(Pasajeros)\", x = \"Fecha\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ ¬øQu√© esperamos ver?\n",
    "\n",
    "* La **l√≠nea negra** representa la serie log-transformada observada.\n",
    "* La **l√≠nea azul discontinua** es la tendencia suavizada estimada por el modelo.\n",
    "* Se espera que la tendencia siga el movimiento de fondo de la serie, **ignorando la estacionalidad** y el ruido aleatorio.\n",
    "\n",
    "> üìå Esta descomposici√≥n permite **interpretar el comportamiento subyacente** de la serie, separado de los efectos c√≠clicos y de corto plazo.\n",
    "\n",
    "### üìä **5. Visualizaci√≥n del componente estacional**\n",
    "\n",
    "Una de las ventajas clave de los modelos de estado espacial es su capacidad para estimar la **componente estacional de forma separada y din√°mica**, lo que permite analizar su comportamiento a lo largo del tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßÆ Extracci√≥n de la estacionalidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sumar los 11 efectos estacionales (uno por cada dummy)\n",
    "estacionalidad_total <- rowSums(kfs$alphahat[, grepl(\"sea_dummy\", colnames(kfs$alphahat))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç Cada fila de `kfs$alphahat` contiene los valores suavizados de los estados latentes. Al sumar los efectos `sea_dummy1` a `sea_dummy11`, se reconstruye la estacionalidad total en cada punto del tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßæ Construcci√≥n de la serie temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convertir a serie ts con la misma estructura que log_ap\n",
    "ts_estacionalidad <- ts(estacionalidad_total, start = start(log_ap), frequency = frequency(log_ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìÜ Conversi√≥n a data.frame para graficar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Crear data.frame con fechas y valores estacionales\n",
    "df_est <- data.frame(\n",
    "  Fecha = as.Date(as.yearmon(time(ts_estacionalidad))),\n",
    "  Estacionalidad = as.numeric(ts_estacionalidad)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Graficar la estacionalidad suavizada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualizaci√≥n\n",
    "ggplot(df_est, aes(x = Fecha, y = Estacionalidad)) +\n",
    "  geom_line(color = \"darkgreen\", linewidth = 0.8) +\n",
    "  labs(title = \"Componente Estacional Suavizado (Modelo de Estado Espacial)\",\n",
    "       x = \"Fecha\", y = \"Estacionalidad\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Interpretaci√≥n esperada\n",
    "\n",
    "* El gr√°fico muestra c√≥mo var√≠a la estacionalidad mes a mes a lo largo del tiempo.\n",
    "* Se espera observar un patr√≥n **c√≠clico repetitivo**, con meses consistentemente positivos (por ejemplo, junio‚Äìagosto) y otros negativos (enero, noviembre, etc.).\n",
    "* La estacionalidad suavizada puede variar ligeramente entre a√±os, permitiendo capturar **din√°micas estacionales no estrictamente constantes**.\n",
    "\n",
    "> üß† Este tipo de representaci√≥n es √∫til para **detectar cambios sutiles en la estructura estacional** a lo largo del tiempo.\n",
    "\n",
    "### üìà **6. Generaci√≥n de pron√≥sticos con modelo de estado espacial**\n",
    "\n",
    "Una vez ajustado el modelo e interpretados los componentes latentes, es posible generar **pron√≥sticos fuera de muestra** y sus respectivos **intervalos de predicci√≥n**. Esto se realiza f√°cilmente gracias a la estructura probabil√≠stica del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÆ Generar pron√≥stico a 24 meses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicci√≥n en escala logar√≠tmica (con intervalo del 95%)\n",
    "pred_kfas <- predict(modelo_ajustado, n.ahead = 24, interval = \"prediction\", level = 0.95)\n",
    "\n",
    "# Transformar de log-escala a escala original (pasajeros)\n",
    "pred_exp <- exp(pred_kfas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç `predict()` entrega un objeto con tres columnas:\n",
    "\n",
    "* `\"fit\"`: valor pronosticado.\n",
    "* `\"lwr\"` y `\"upr\"`: l√≠mites inferior y superior del intervalo de predicci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßæ Visualizaci√≥n junto a la serie hist√≥rica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar pron√≥stico junto a la serie observada\n",
    "forecast::autoplot(window(ap, end = c(1960, 12))) +\n",
    "  autolayer(ts(pred_exp[, \"fit\"], start = c(1961, 1), frequency = 12), series = \"Pron√≥stico\") +\n",
    "  autolayer(ts(pred_exp[, \"lwr\"], start = c(1961, 1), frequency = 12), series = \"L√≠mite inferior\", linetype = \"dashed\") +\n",
    "  autolayer(ts(pred_exp[, \"upr\"], start = c(1961, 1), frequency = 12), series = \"L√≠mite superior\", linetype = \"dashed\") +\n",
    "  labs(title = \"Pron√≥stico con modelo de estado espacial\",\n",
    "       y = \"Pasajeros\", x = \"A√±o\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì§ Visualizar **solo el pron√≥stico**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n solo del pron√≥stico y sus intervalos\n",
    "forecast::autoplot(ts(pred_exp[, \"fit\"], start = c(1961, 1), frequency = 12), series = \"Pron√≥stico\") +\n",
    "  autolayer(ts(pred_exp[, \"lwr\"], start = c(1961, 1), frequency = 12), series = \"L√≠mite inferior\", linetype = \"dashed\") +\n",
    "  autolayer(ts(pred_exp[, \"upr\"], start = c(1961, 1), frequency = 12), series = \"L√≠mite superior\", linetype = \"dashed\") +\n",
    "  labs(title = \"Pron√≥stico con modelo de estado espacial\",\n",
    "       y = \"Pasajeros\", x = \"A√±o\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Interpretaci√≥n esperada\n",
    "\n",
    "* El modelo genera un **pron√≥stico suavizado** que **respeta la tendencia creciente y la estacionalidad** capturada.\n",
    "* Las **bandas de predicci√≥n** reflejan la **incertidumbre creciente** a medida que se avanza en el horizonte.\n",
    "* Este comportamiento es **t√≠pico de modelos estructurales** con m√∫ltiples componentes latentes.\n",
    "\n",
    "## ü§ñ Redes Neuronales aplicadas a Series Temporales\n",
    "\n",
    "Las redes neuronales permiten modelar relaciones no lineales complejas entre los valores pasados de una serie y su comportamiento futuro. Aunque no est√°n dise√±adas espec√≠ficamente para datos secuenciales como los modelos de estado espacial o ARIMA, pueden capturar patrones ocultos √∫tiles para la predicci√≥n, especialmente si se utilizan ventanas de entrada (lags) adecuadas.\n",
    "\n",
    "En esta secci√≥n trabajaremos con la serie `AirPassengers`, previamente transformada para estabilizar la varianza, y exploraremos diferentes enfoques neuronales para el pron√≥stico.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ **1. Transformaci√≥n logar√≠tmica y visualizaci√≥n inicial**\n",
    "\n",
    "Antes de aplicar cualquier red neuronal, transformamos la serie a logaritmo natural para facilitar la modelaci√≥n y evitar predicciones negativas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaci√≥n logar√≠tmica\n",
    "log_ap <- log(AirPassengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Visualizaci√≥n de la serie transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "library(ggplot2)\n",
    "\n",
    "autoplot(log_ap) +\n",
    "  labs(title = \"Serie log-transformada: AirPassengers\",\n",
    "       y = \"log(Pasajeros)\", x = \"A√±o\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† ¬øPor qu√© usar el logaritmo?\n",
    "\n",
    "* La transformaci√≥n suaviza la **amplitud creciente de la estacionalidad**.\n",
    "* Permite que modelos con salida lineal (como `nnet`) trabajen de manera m√°s estable.\n",
    "* Las predicciones en log-escala pueden transformarse de vuelta a escala original con `exp()`.\n",
    "\n",
    "### ‚öôÔ∏è **2. Modelo autoregresivo neuronal con `nnetar()`**\n",
    "\n",
    "El paquete `forecast` incluye la funci√≥n `nnetar()`, que ajusta de forma autom√°tica una **red neuronal autoregresiva no lineal (NNAR)**. Este modelo combina la flexibilidad de las redes neuronales con la estructura de los modelos AR tradicionales.\n",
    "\n",
    "---\n",
    "\n",
    "#### ü§ñ Ajustar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_nnetar <- nnetar(log_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modelo se entrena autom√°ticamente seleccionando:\n",
    "\n",
    "  * El n√∫mero de retardos (lags) a usar.\n",
    "  * La cantidad de neuronas en la capa oculta.\n",
    "  * Si se incluye o no estacionalidad expl√≠cita.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç Ver resumen del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_nnetar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Este comando muestra la arquitectura utilizada (por ejemplo, NNAR(1,1,2)\\[12]) y cu√°ntas redes fueron promediadas para estabilizar el resultado.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÆ Generar pron√≥stico a 24 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pron_nnetar <- forecast(modelo_nnetar, h = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Visualizar el pron√≥stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoplot(pron_nnetar) +\n",
    "  labs(title = \"Pron√≥stico con red neuronal autoregresiva (nnetar)\",\n",
    "       y = \"log(Pasajeros)\", x = \"A√±o\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Interpretaci√≥n esperada\n",
    "\n",
    "* El modelo genera una **serie suavizada de pron√≥sticos** en log-escala, incluyendo bandas de predicci√≥n.\n",
    "* Se espera que la red capture tanto la **tendencia global** como **patrones estacionales**, aunque puede suavizarlos en exceso si la arquitectura es muy simple.\n",
    "\n",
    "> üìå `nnetar()` es una excelente herramienta para establecer un baseline no lineal, sin necesidad de configurar manualmente la red.\n",
    "\n",
    "### ‚öôÔ∏è **3. Red neuronal personalizada con `nnet()`**\n",
    "\n",
    "En esta etapa construiremos manualmente una red neuronal para pron√≥stico utilizando la funci√≥n `nnet()` del paquete base. A diferencia de `nnetar()`, este enfoque nos permite **definir directamente la estructura de entrada y controlar el entrenamiento** paso a paso.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßÆ Crear matriz de entrada (ventana de 12 lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(nnet)\n",
    "library(tibble)\n",
    "\n",
    "# Definir n√∫mero de retardos\n",
    "lags <- 12\n",
    "\n",
    "# Construir matriz con lags + objetivo\n",
    "x <- embed(log_ap, lags + 1)\n",
    "y <- x[, 1]         # valor objetivo\n",
    "X <- x[, -1]        # variables predictoras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìå `embed()` crea una matriz en la que cada fila contiene los 12 valores anteriores (lagged inputs) y la respuesta.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÇÔ∏è Separar conjunto de entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos todos los datos excepto los √∫ltimos 24 para entrenar\n",
    "n <- nrow(X)\n",
    "train_idx <- 1:(n - 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß† Ajustar el modelo con `nnet()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar red neuronal: 12 entradas, 5 neuronas ocultas, salida lineal\n",
    "modelo_nnet <- nnet(X[train_idx, ], y[train_idx],\n",
    "                    size = 5, linout = TRUE, trace = FALSE)\n",
    "\n",
    "# Revisar estructura de la red\n",
    "modelo_nnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ ¬øQu√© hace esta red?\n",
    "\n",
    "* **Arquitectura**: 12‚Äì5‚Äì1 (12 entradas, 5 nodos ocultos, 1 salida).\n",
    "* **Activaci√≥n**: funciones no lineales en capa oculta, salida lineal (`linout = TRUE`).\n",
    "* Entrenada sobre datos escalados en log-escala, con 24 valores reservados para prueba.\n",
    "* Sin validaci√≥n cruzada autom√°tica, por lo que es **m√°s sensible a sobreajuste**.\n",
    "\n",
    "### üîÆ **4. Pron√≥stico recursivo con red neuronal personalizada (`nnet`)**\n",
    "\n",
    "Una vez entrenado el modelo con una ventana deslizante de 12 retardos, generamos el pron√≥stico fuera de muestra **de manera recursiva**, es decir, alimentando el modelo con sus propias predicciones.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Generar pron√≥stico a 24 pasos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar vector para almacenar predicciones\n",
    "pred <- numeric(24)\n",
    "\n",
    "# Tomar como entrada la √∫ltima fila disponible del conjunto de entrenamiento\n",
    "input <- X[n - 24, ]\n",
    "\n",
    "# Pron√≥stico recursivo: una predicci√≥n alimenta la siguiente\n",
    "for (i in 1:24) {\n",
    "  pred[i] <- predict(modelo_nnet, matrix(input, nrow = 1))\n",
    "  input <- c(pred[i], head(input, -1))  # actualizar entrada\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìå Este enfoque simula un escenario real de pron√≥stico, donde no se conocen los valores futuros verdaderos y el modelo debe apoyarse en sus propias salidas.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÑ Transformar y organizar resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volver a escala original (pasajeros)\n",
    "pred_exp <- exp(pred)\n",
    "\n",
    "# Construir fechas de predicci√≥n\n",
    "fechas_pred <- seq(as.Date(\"1961-01-01\"), by = \"month\", length.out = 24)\n",
    "\n",
    "# Data frame de predicci√≥n\n",
    "df_pred <- data.frame(Fecha = fechas_pred, Pronostico = pred_exp)\n",
    "\n",
    "# Serie hist√≥rica\n",
    "df_hist <- data.frame(\n",
    "  Fecha = as.Date(as.yearmon(time(AirPassengers))),\n",
    "  Pasajeros = as.numeric(AirPassengers)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Visualizaci√≥n del pron√≥stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "ggplot() +\n",
    "  geom_line(data = df_hist, aes(x = Fecha, y = Pasajeros), color = \"black\") +\n",
    "  geom_line(data = df_pred, aes(x = Fecha, y = Pronostico), color = \"blue\") +\n",
    "  labs(title = \"Pron√≥stico con red neuronal simple (`nnet`)\",\n",
    "       y = \"Pasajeros\", x = \"Fecha\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ ¬øQu√© observamos?\n",
    "\n",
    "* La red logra continuar el patr√≥n de crecimiento, aunque en general:\n",
    "\n",
    "  * **Subestima la amplitud de la estacionalidad**.\n",
    "  * Puede presentar **explosiones o colapsos** si no est√° bien regularizada.\n",
    "* Este comportamiento es t√≠pico en redes **alimentadas recursivamente sin control de error acumulado**.\n",
    "\n",
    "> ‚ö†Ô∏è Para mejorar este enfoque, se podr√≠an usar t√©cnicas de regularizaci√≥n, validaci√≥n cruzada o redes con memoria como las recurrentes (`RSNNS`).\n",
    "\n",
    "### üß™ **5. Red neuronal con validaci√≥n cruzada (`caret`)**\n",
    "\n",
    "El paquete `caret` permite entrenar redes neuronales con control expl√≠cito de validaci√≥n cruzada para datos temporales. En este caso, usaremos **12 retardos como predictores** y una estrategia de validaci√≥n tipo *time slice*, adecuada para series temporales.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßÆ Construcci√≥n del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "\n",
    "# Crear matriz de datos con lags como predictores\n",
    "data_nnet <- as.data.frame(embed(log_ap, 13))\n",
    "colnames(data_nnet) <- c(\"y\", paste0(\"lag\", 1:12))\n",
    "\n",
    "# Conjunto de entrenamiento (excluye los √∫ltimos 24 puntos)\n",
    "train_nnet <- data_nnet[1:(nrow(data_nnet) - 24), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìå Usamos 12 lags como variables independientes, y el valor actual como variable objetivo (`y`).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öôÔ∏è Definir estrategia de validaci√≥n cruzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control <- trainControl(\n",
    "  method = \"timeslice\",\n",
    "  initialWindow = 96,\n",
    "  horizon = 12,\n",
    "  fixedWindow = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se utiliza un enfoque tipo **rolling forecasting origin**, que:\n",
    "\n",
    "  * Mantiene una ventana de entrenamiento fija.\n",
    "  * Eval√∫a el modelo en m√∫ltiples puntos del tiempo.\n",
    "  * Es coherente con la estructura temporal de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Entrenar la red neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "modelo_caret <- train(\n",
    "  y ~ ., data = train_nnet,\n",
    "  method = \"nnet\",\n",
    "  linout = TRUE,\n",
    "  trace = FALSE,\n",
    "  tuneLength = 5,\n",
    "  trControl = control\n",
    ")\n",
    "\n",
    "modelo_caret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tuneLength = 5` explora autom√°ticamente combinaciones de:\n",
    "\n",
    "  * N√∫mero de neuronas ocultas (`size`).\n",
    "  * Par√°metro de regularizaci√≥n (`decay`).\n",
    "* Se selecciona el modelo con menor RMSE en validaci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÆ Generar predicciones fuera de muestra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √öltimos 24 registros (lagged inputs) como test\n",
    "X_pred <- tail(data_nnet, 24)[, -1]\n",
    "\n",
    "# Predicci√≥n en log-escala\n",
    "pred_caret <- predict(modelo_caret, newdata = X_pred)\n",
    "\n",
    "# Transformar a escala original\n",
    "fechas_pred <- seq(as.Date(\"1961-01-01\"), by = \"month\", length.out = 24)\n",
    "df_pred_caret <- data.frame(\n",
    "  Fecha = fechas_pred,\n",
    "  Pronostico = exp(pred_caret)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Visualizaci√≥n del pron√≥stico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_line(data = df_hist, aes(x = Fecha, y = Pasajeros), color = \"black\") +\n",
    "  geom_line(data = df_pred_caret, aes(x = Fecha, y = Pronostico), color = \"blue\") +\n",
    "  labs(title = \"Pron√≥stico con red neuronal (`caret`)\", y = \"Pasajeros\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Interpretaci√≥n esperada\n",
    "\n",
    "* El modelo se beneficia del proceso de validaci√≥n cruzada, ajustando mejor la capacidad de generalizaci√≥n.\n",
    "* Sin embargo, como depende solo de rezagos, **puede fallar al capturar estacionalidad compleja** o al mantener la tendencia con precisi√≥n en el largo plazo.\n",
    "* La visualizaci√≥n permite detectar **desviaciones sistem√°ticas** y comparar con pron√≥sticos anteriores (`nnet`, `nnetar`).\n",
    "\n",
    "## üîÅ **6. Red neuronal recurrente con `RSNNS` (Elman)**\n",
    "\n",
    "Las redes Elman son un tipo de **red neuronal recurrente (RNN)** que incorporan memoria corta mediante conexiones de retroalimentaci√≥n. Son √∫tiles para series temporales ya que pueden capturar **dependencias m√°s profundas** que los modelos feedforward.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Entrenar la red Elman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(RSNNS)\n",
    "\n",
    "modelo_rsnns <- elman(\n",
    "  X[train_idx, ], y[train_idx],\n",
    "  size = c(5),\n",
    "  learnFuncParams = c(0.1),\n",
    "  maxit = 100\n",
    ")\n",
    "\n",
    "modelo_rsnns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÆ Pron√≥stico recursivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rsnns <- numeric(24)\n",
    "input <- X[n - 24, ]\n",
    "\n",
    "for (i in 1:24) {\n",
    "  pred_rsnns[i] <- predict(modelo_rsnns, matrix(input, nrow = 1))\n",
    "  input <- c(pred_rsnns[i], head(input, -1))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Visualizaci√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_rsnns <- data.frame(\n",
    "  Fecha = fechas_pred,\n",
    "  Pronostico = exp(pred_rsnns)\n",
    ")\n",
    "\n",
    "ggplot() +\n",
    "  geom_line(data = df_hist, aes(x = Fecha, y = Pasajeros), color = \"black\") +\n",
    "  geom_line(data = df_pred_rsnns, aes(x = Fecha, y = Pronostico), color = \"darkred\") +\n",
    "  labs(title = \"Pron√≥stico con red neuronal recurrente (`RSNNS`)\", y = \"Pasajeros\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Observaciones esperadas\n",
    "\n",
    "* Las RNN pueden **capturar patrones de dependencia m√°s largos**, pero:\n",
    "\n",
    "  * Requieren m√°s datos y entrenamiento m√°s prolongado.\n",
    "  * Son sensibles a la inicializaci√≥n y n√∫mero de iteraciones (`maxit`).\n",
    "* La red puede producir **pron√≥sticos planos** si no logra aprender la estructura estacional.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ **7. Red autoregresiva con `tsDyn::nnetTs`**\n",
    "\n",
    "`tsDyn` ofrece una forma r√°pida de ajustar redes autoregresivas con una interfaz especializada para series temporales.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Ajustar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tsDyn)\n",
    "\n",
    "modelo_tsDyn <- nnetTs(log_ap[1:(length(log_ap) - 24)], m = 12, size = 5)\n",
    "modelo_tsDyn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÆ Generar pron√≥stico a 24 pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tsDyn <- predict(modelo_tsDyn, n.ahead = 24)\n",
    "\n",
    "df_pred_tsDyn <- data.frame(\n",
    "  Fecha = fechas_pred,\n",
    "  Pronostico = exp(pred_tsDyn)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_line(data = df_hist, aes(x = Fecha, y = Pasajeros), color = \"black\") +\n",
    "  geom_line(data = df_pred_tsDyn, aes(x = Fecha, y = Pronostico), color = \"purple\") +\n",
    "  labs(title = \"Pron√≥stico con red neuronal autoregresiva (`tsDyn`)\", y = \"Pasajeros\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Comentarios esperados\n",
    "\n",
    "* `tsDyn` facilita el ajuste y predicci√≥n sin pasos manuales, ideal para exploraci√≥n r√°pida.\n",
    "* Puede generar **pron√≥sticos razonables**, pero **no incluye validaci√≥n cruzada ni regularizaci√≥n expl√≠cita**.\n",
    "* A diferencia de `caret` o `nnetar`, **el modelo es sensible al sobreajuste y a la amplitud de los lags**.\n",
    "\n",
    "### üí¨ Preguntas\n",
    "\n",
    "1.  ¬øQu√© ventajas ofrece el modelo de estado espacial frente a las redes neuronales cuando se busca descomponer una serie temporal en tendencia y estacionalidad? \n",
    "2.  ¬øPor qu√© es importante aplicar la transformaci√≥n logar√≠tmica antes de ajustar redes neuronales a la serie `AirPassengers`? ¬øQu√© podr√≠a pasar si no se realiza? \n",
    "3.  En el modelo `nnetar()`, ¬øc√≥mo se interpreta la notaci√≥n NNAR(1,1,2)\\[12]? ¬øQu√© representa cada n√∫mero? \n",
    "4.  ¬øCu√°l es la diferencia clave entre los pron√≥sticos generados con `nnetar()` y los obtenidos con `nnet()` manual? ¬øQu√© riesgos introduce la predicci√≥n recursiva? \n",
    "5.  ¬øQu√© rol juega la validaci√≥n cruzada tipo *rolling forecasting origin* utilizada con `caret`? ¬øEn qu√© se diferencia de una validaci√≥n cruzada tradicional? \n",
    "6.  Al comparar los resultados de `RSNNS` y `tsDyn`, ¬øpor qu√© puede fallar una red neuronal en capturar adecuadamente la estacionalidad o la tendencia, incluso si tiene una arquitectura similar a otros modelos que s√≠ lo logran? \n",
    "\n",
    "## üìê Modelos Aditivos Generalizados (GAMs) con `mgcv`\n",
    "\n",
    "Los modelos GAM permiten modelar series temporales de manera **flexible y estructurada**, separando la tendencia del tiempo y la estacionalidad mediante funciones suavizadas. Esta t√©cnica es especialmente √∫til cuando no se desea imponer una estructura param√©trica r√≠gida.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è **1. Preparaci√≥n de datos**\n",
    "\n",
    "Transformamos la serie `AirPassengers` en un `tibble` con variables expl√≠citas para a√±o, mes, tiempo y logaritmo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(mgcv)\n",
    "library(tibble)\n",
    "library(dplyr)\n",
    "\n",
    "df_ap <- tibble(\n",
    "  Fecha = as.Date(as.yearmon(time(AirPassengers))),\n",
    "  A√±o = as.numeric(format(Fecha, \"%Y\")),\n",
    "  Mes = as.numeric(format(Fecha, \"%m\")),\n",
    "  Tiempo = 1:length(AirPassengers),\n",
    "  Pasajeros = as.numeric(AirPassengers),\n",
    "  LogPasajeros = log(Pasajeros)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† **2. Ajustar modelo GAM**\n",
    "\n",
    "Usamos dos funciones suavizadas:\n",
    "\n",
    "* `s(Tiempo)`: para capturar la **tendencia**.\n",
    "* `s(Mes, bs = \"cc\")`: para modelar la **estacionalidad c√≠clica**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_gam <- gam(LogPasajeros ~ s(Tiempo, k = 20) + s(Mes, bs = \"cc\", k = 12),\n",
    "                  data = df_ap,\n",
    "                  method = \"REML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã **3. Evaluar y visualizar el modelo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(modelo_gam)\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "plot(modelo_gam, shade = TRUE, seWithMean = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Verifica la **significancia de los t√©rminos suavizados**, el **R¬≤ ajustado** y la **forma de los componentes suavizados** (tendencia y estacionalidad).\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ **4. Visualizar el ajuste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap$Ajuste <- fitted(modelo_gam)\n",
    "\n",
    "ggplot(df_ap, aes(x = Fecha)) +\n",
    "  geom_line(aes(y = LogPasajeros), color = \"black\") +\n",
    "  geom_line(aes(y = Ajuste), color = \"blue\") +\n",
    "  labs(title = \"GAM: Ajuste de log(Pasajeros)\",\n",
    "       y = \"log(Pasajeros)\", x = \"Fecha\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÆ **5. Generar predicci√≥n a 24 meses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas fechas\n",
    "ultimo_tiempo <- max(df_ap$Tiempo)\n",
    "fechas_futuras <- seq(from = max(df_ap$Fecha) + 1, by = \"month\", length.out = 24)\n",
    "\n",
    "# Armar data.frame de predicci√≥n\n",
    "df_pred <- tibble(\n",
    "  Fecha = fechas_futuras,\n",
    "  Tiempo = (ultimo_tiempo + 1):(ultimo_tiempo + 24),\n",
    "  Mes = as.numeric(format(fechas_futuras, \"%m\"))\n",
    ")\n",
    "\n",
    "# Predicci√≥n en log-escala con errores est√°ndar\n",
    "pred_log <- predict(modelo_gam, newdata = df_pred, se.fit = TRUE)\n",
    "\n",
    "# Transformar a escala original\n",
    "df_pred <- df_pred %>%\n",
    "  mutate(\n",
    "    LogPred = pred_log$fit,\n",
    "    LogLI = LogPred - 1.96 * pred_log$se.fit,\n",
    "    LogLS = LogPred + 1.96 * pred_log$se.fit,\n",
    "    Pred = exp(LogPred),\n",
    "    LI = exp(LogLI),\n",
    "    LS = exp(LogLS)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà **6. Visualizar predicci√≥n final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "  geom_line(data = df_ap, aes(x = Fecha, y = Pasajeros), color = \"black\") +\n",
    "  geom_line(data = df_pred, aes(x = Fecha, y = Pred), color = \"blue\") +\n",
    "  geom_ribbon(data = df_pred, aes(x = Fecha, ymin = LI, ymax = LS), alpha = 0.2, fill = \"blue\") +\n",
    "  labs(title = \"Predicci√≥n a 24 meses con GAM\",\n",
    "       x = \"Fecha\", y = \"Pasajeros (escala original)\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ ¬øQu√© observamos?\n",
    "\n",
    "* El GAM logra capturar tanto la **tendencia suave** como la **estacionalidad c√≠clica mensual**.\n",
    "* Las bandas de predicci√≥n reflejan la **incertidumbre estimada** por el modelo.\n",
    "* Es un modelo **explicativo e interpretable**, ideal para **an√°lisis estructural y visualizaci√≥n**, aunque limitado en tareas de forecasting puro.\n",
    "\n",
    "## üí¨  Preguntas para discusi√≥n final del taller \n",
    "\n",
    "### üìå Comparaci√≥n y aplicaci√≥n de modelos\n",
    "\n",
    "1.  ¬øCu√°l de los tres enfoques modela de forma m√°s transparente la estructura de una serie temporal? ¬øPor qu√©? \n",
    "   *(Considera descomposici√≥n expl√≠cita, interpretabilidad y flexibilidad.)*\n",
    "2.  ¬øQu√© tipo de modelo usar√≠as si tuvieras una serie con cambios de r√©gimen, intervenciones o datos faltantes? Justifica tu respuesta. \n",
    "3.  Si tu objetivo principal es la precisi√≥n del pron√≥stico en el corto plazo, ¬øcu√°l modelo preferir√≠as y por qu√©? \n",
    "\n",
    "---\n",
    "\n",
    "### üß† Reflexi√≥n metodol√≥gica\n",
    "\n",
    "4.  ¬øQu√© riesgos implica utilizar pron√≥sticos recursivos con redes neuronales como `nnet()` o `RSNNS`? ¬øC√≥mo podr√≠an mitigarse? \n",
    "5.  ¬øC√≥mo se diferencia el enfoque de estacionalidad en los GAMs respecto al modelo de estado espacial y las redes neuronales autoregresivas? \n",
    "6.  ¬øCrees que combinar estos enfoques (por ejemplo, GAM + RNN o GAM + estado espacial) podr√≠a ser √∫til en alg√∫n contexto? ¬øQu√© ganar√≠as o perder√≠as con dicha combinaci√≥n? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
